---
layout: page
permalink: /miscellaneous/
title: miscellaneous
description:
nav: true
nav_order: 6
---

### My tutorials

* [A brief overview of proximal algorithms](/files/ProximalAlgorithms.pdf){:target="_blank" rel="noopener"}
* A simple derivation of the backpropagation (backprop) algorithm for training artificial neural networks in matrix form can be found [here](/files/BackpropMatrixForm.pdf){:target="_blank" rel="noopener"}.
* For a brief tutorial on gradient backpropagation through a long short-term memory (LSTM) cell, see [this](/files/lstm.pdf){:target="_blank" rel="noopener"}.
* A simple [demo](/files/Sparse Demo.zip){:target="_blank" rel="noopener"} of *Sparse Land*, including, various sparse signal recovery (compressed sensing) algorithms, demonstration of simple dimensionality reduction schemes based on *Discrete Cosine Transform (DCT)* and *Principal Component Analysis (PCA)*, and so on.

### Interesting resources on deep learning

* [Machine learning, deep learning, and artificial intelligence easy-to-digest cheatsheets](https://stanford.edu/~shervine/teaching/){:target="_blank" rel="noopener"}
* [A very nice browser-based platform for training and visualizing deep networks](https://cs.stanford.edu/people/karpathy/convnetjs/){:target="_blank" rel="noopener"}
* [A neural network playground!](https://playground.tensorflow.org/){:target="_blank" rel="noopener"}
* [Visualizing and understanding what different layers in a CNN are learning!](http://yosinski.com/deepvis){:target="_blank" rel="noopener"}
* [A very nice and well-explained tutorial on Variational Auto-encoders (VAEs)!](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf){:target="_blank" rel="noopener"} + Take also a look at [this one](https://szhao.me/a-tutorial-on-mmd-variational-autoencoders/){:target="_blank" rel="noopener"}
* [Machine Learning Notebooks](https://github.com/ageron/handson-ml2){:target="_blank" rel="noopener"}
* [Blog posts on deep generative models](https://jmtomczak.github.io/blog.html){:target="_blank" rel="noopener"}
* [Convolution Visualizer](https://ezyang.github.io/convolution-visualizer/index.html){:target="_blank" rel="noopener"}

### Some random interesting articles

* [Bayesian inference for hiring!](https://triplebyte.com/blog/bayesian-inference-for-hiring-engineers){:target="_blank" rel="noopener"}
* [A very nice comparison of frequentist and Bayesian inference](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf){:target="_blank" rel="noopener"} + [Explaining it via a fictional dialogue](https://www.quora.com/For-a-non-expert-what-is-the-difference-between-Bayesian-and-frequentist-approaches/answer/Jason-Eisner){:target="_blank" rel="noopener"}
* [A great blog post that explains backpropagation through computational graphs in a very simple way!](http://colah.github.io/posts/2015-08-Backprop/){:target="_blank" rel="noopener"}
* [For an introduction to the calculus of variations, see this nice post and the references therein](http://bjlkeng.github.io/posts/the-calculus-of-variations/){:target="_blank" rel="noopener"}
* [A nice book to learn Python for data science](https://jakevdp.github.io/PythonDataScienceHandbook/){:target="_blank" rel="noopener"} + Check [this post](https://www.linkedin.com/feed/update/activity:6448184477805084672/){:target="_blank" rel="noopener"} + [CS231 course](https://cs231n.github.io/python-numpy-tutorial/){:target="_blank" rel="noopener"}
* [Computational Statistics in Python](http://people.duke.edu/~ccc14/sta-663-2017/){:target="_blank" rel="noopener"}
* [Approximate inference in Bayesian Learning](http://www.mit.edu/~9.520/spring11/slides/class19_approxinf.pdf){:target="_blank" rel="noopener"}
* [Derivations for Linear Algebra and Optimization](https://sites.google.com/site/msaadeghii23/general_notes_Derivations%20for%20Linear%20Algebra%20and%20Optimization.pdf?attredirects=0&d=1){:target="_blank" rel="noopener"}
* [A nice blog post on Markov Chain Monte Carlo techniques](http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html){:target="_blank" rel="noopener"}
* An interesting and well-written overview paper about non-convex optimization for low-rank matrix factorization: [Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview](https://ieeexplore.ieee.org/document/8811622){:target="_blank" rel="noopener"}
* [A very nice document on optimization for machine learning](https://mathematical-tours.github.io/book-sources/optim-ml/OptimML.pdf){:target="_blank" rel="noopener"}

### Approximating intractable KL divergences
* [Gaussian Kullback-Leibler Approximate Inference](http://www.jmlr.org/papers/volume14/challis13a/challis13a.pdf){:target="_blank" rel="noopener"}
* [Approximating the Kullback Leibler Divergence Between Gaussian Mixture Models](https://ieeexplore.ieee.org/document/4218101){:target="_blank" rel="noopener"}
* [Non-Gaussian likelihoods for Gaussian Processes](http://gpss.cc/gpss15/talks/gpss_non_gaussian-2.pdf){:target="_blank" rel="noopener"}
* [Approximating the KL divergence between two densities using gamma-divergence](https://www.researchgate.net/publication/339663864_On_estimating_the_Kullback-Leibler_divergence_between_two_densities_with_computationally_intractable_normalization_factors){:target="_blank" rel="noopener"}

### Some useful books

* [Information Theory, Inference and Learning Algorithms](http://www.inference.org.uk/itila/book.html){:target="_blank" rel="noopener"} (by D. MacKay)
* [Introduction to Applied Linear Algebra](https://web.stanford.edu/~boyd/vmls/vmls.pdf){:target="_blank" rel="noopener"} (by S. Boyd and L. Vandenberghe)
* [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf){:target="_blank" rel="noopener"} (a must-have handbook!)

### Some helpful notes

* [You and Your Research](https://www.youtube.com/watch?v=a1zDuOPkMSw){:target="_blank" rel="noopener"} + [A stroke of genius](https://www.cs.utexas.edu/users/dahlin/bookshelf/hamming.html){:target="_blank" rel="noopener"}

* [How to write the introduction for a research paper](https://sites.google.com/site/msaadeghii23/How%20to%20write%20the%20introduction.pdf?attredirects=0&d=1){:target="_blank" rel="noopener"} (by Kate Saenko)

* [Coding Interview University](https://github.com/jwasham/coding-interview-university){:target="_blank" rel="noopener"}
